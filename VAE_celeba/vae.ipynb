{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000', '000001', '000002', '000003', '000004', '000005', '000006', '000007', '000008', '000009', '000010', '000011', '000012', '000013', '000014', '000015', '000016', '000017', '000018', '000019', '000020', '000021', '000022', '000023', '000024', '000025', '000026', '000027', '000028', '000029', '000030', '000031', '000032', '000033', '000034', '000035', '000036', '000037', '000038', '000039', '000040', '000041', '000042', '000043', '000044', '000045', '000046', '000047', '000048', '000049', '000050', '000051', '000052', '000053', '000054', '000055', '000056', '000057', '000058', '000059', '000060', '000061', '000062', '000063', '000064', '000065', '000066', '000067', '000068', '000069', '000070', '000071', '000072', '000073', '000074', '000075', '000076', '000077', '000078', '000079', '000080', '000081', '000082', '000083', '000084', '000085', '000086', '000087', '000088', '000089', '000090', '000091', '000092', '000093', '000094', '000095', '000096', '000097', '000098', '000099', '000100', '000101', '000102', '000103', '000104', '000105', '000106', '000107', '000108', '000109', '000110', '000111', '000112', '000113', '000114', '000115', '000116', '000117', '000118', '000119', '000120', '000121', '000122', '000123', '000124', '000125', '000126', '000127']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peter/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:173: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.Upsample instead.\n",
      "  warnings.warn(\"nn.UpsamplingNearest2d is deprecated. Use nn.Upsample instead.\")\n",
      "/Users/peter/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([128, 3, 128, 105])) that is different to the input size (torch.Size([105, 3, 128, 128])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/Users/peter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:189: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/peter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:195: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/266240 (0%)]\tLoss: 28627.740234\n",
      "['000128', '000129', '000130', '000131', '000132', '000133', '000134', '000135', '000136', '000137', '000138', '000139', '000140', '000141', '000142', '000143', '000144', '000145', '000146', '000147', '000148', '000149', '000150', '000151', '000152', '000153', '000154', '000155', '000156', '000157', '000158', '000159', '000160', '000161', '000162', '000163', '000164', '000165', '000166', '000167', '000168', '000169', '000170', '000171', '000172', '000173', '000174', '000175', '000176', '000177', '000178', '000179', '000180', '000181', '000182', '000183', '000184', '000185', '000186', '000187', '000188', '000189', '000190', '000191', '000192', '000193', '000194', '000195', '000196', '000197', '000198', '000199', '000200', '000201', '000202', '000203', '000204', '000205', '000206', '000207', '000208', '000209', '000210', '000211', '000212', '000213', '000214', '000215', '000216', '000217', '000218', '000219', '000220', '000221', '000222', '000223', '000224', '000225', '000226', '000227', '000228', '000229', '000230', '000231', '000232', '000233', '000234', '000235', '000236', '000237', '000238', '000239', '000240', '000241', '000242', '000243', '000244', '000245', '000246', '000247', '000248', '000249', '000250', '000251', '000252', '000253', '000254', '000255']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "from util import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch VAE')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=20, metavar='N',\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = range(2080)\n",
    "test_loader = range(40)\n",
    "\n",
    "totensor = transforms.ToTensor()\n",
    "def load_batch(batch_idx, istrain):\n",
    "    size = 128, 128, 3\n",
    "    if istrain:\n",
    "        template = '/Users/peter/Desktop/VAE_celeba/data/train/%s.jpg'\n",
    "    else:\n",
    "        template = '/Users/peter/Desktop/VAE_celeba/data/test/%s.jpg'\n",
    "    l = [str(batch_idx*128 + i).zfill(6) for i in range(128)]\n",
    "    print(l)\n",
    "    data = []\n",
    "    for idx in l:\n",
    "        img = Image.open(template%idx)\n",
    "        img.thumbnail(size)\n",
    "        data.append(np.array(img))\n",
    "    data = [totensor(i) for i in data]\n",
    "    return torch.stack(data, dim=0)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.nc = nc # num channels\n",
    "        self.ngf = ngf # num generator filters\n",
    "        self.ndf = ndf # num discriminator filters\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "\n",
    "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "\n",
    "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "\n",
    "        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(latent_variable_size, ngf*8*2*4*4)\n",
    "\n",
    "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd1 = nn.ReplicationPad2d(1)\n",
    "        self.d2 = nn.Conv2d(ngf*8*2, ngf*8, 3, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8, 1.e-3)\n",
    "\n",
    "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd2 = nn.ReplicationPad2d(1)\n",
    "        self.d3 = nn.Conv2d(ngf*8, ngf*4, 3, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
    "\n",
    "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd3 = nn.ReplicationPad2d(1)\n",
    "        self.d4 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
    "\n",
    "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd4 = nn.ReplicationPad2d(1)\n",
    "        self.d5 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
    "\n",
    "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd5 = nn.ReplicationPad2d(1)\n",
    "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
    "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
    "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
    "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
    "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
    "        h5 = h5.view(-1, self.ndf*8*4*4)\n",
    "\n",
    "        return self.fc1(h5), self.fc2(h5)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if args.cuda:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h1 = self.relu(self.d1(z))\n",
    "        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n",
    "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
    "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
    "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
    "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
    "\n",
    "        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar\n",
    "\n",
    "\n",
    "model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=500)\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "reconstruction_function = nn.BCELoss()\n",
    "reconstruction_function.size_average = False\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx in train_loader:\n",
    "        data = load_batch(batch_idx, True)\n",
    "        data = Variable(data)\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), (len(train_loader)*128),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(train_loader)*128)))\n",
    "    return train_loss / (len(train_loader)*128)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for batch_idx in test_loader:\n",
    "        data = load_batch(batch_idx, False)\n",
    "        data = Variable(data, volatile=True)\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "\n",
    "        torchvision.utils.save_image(data.data, '../imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "        torchvision.utils.save_image(recon_batch.data, '../imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(test_loader)*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def perform_latent_space_arithmatics(items): # input is list of tuples of 3 [(a1,b1,c1), (a2,b2,c2)]\n",
    "    #load_last_model()\n",
    "    model.eval()\n",
    "    data = [im for item in items for im in item]\n",
    "    data = [totensor(i) for i in data]\n",
    "    data = torch.stack(data, dim=0)\n",
    "    data = Variable(data, volatile=True)\n",
    "    if args.cuda:\n",
    "        data = data.cuda()\n",
    "    z = model.get_latent_var(data.view(-1, model.nc, model.ndf, model.ngf))\n",
    "    it = iter(z.split(1))\n",
    "    z = zip(it, it, it)\n",
    "    zs = []\n",
    "    numsample = 11\n",
    "    for i,j,k in z:\n",
    "        for factor in np.linspace(0,1,numsample):\n",
    "            zs.append((i-j)*factor+k)\n",
    "    z = torch.cat(zs, 0)\n",
    "    recon = model.decode(z)\n",
    "\n",
    "    it1 = iter(data.split(1))\n",
    "    it2 = [iter(recon.split(1))]*numsample\n",
    "    result = zip(it1, it1, it1, *it2)\n",
    "    result = [im for item in result for im in item]\n",
    "\n",
    "    result = torch.cat(result, 0)\n",
    "    torchvision.utils.save_image(result.data, '../imgs/vec_math.jpg', nrow=3+numsample, padding=2)\n",
    "\n",
    "\n",
    "def latent_space_transition(items): # input is list of tuples of  (a,b)\n",
    "    #load_last_model()\n",
    "    model.eval()\n",
    "    data = [im for item in items for im in item[:-1]]\n",
    "    data = [totensor(i) for i in data]\n",
    "    data = torch.stack(data, dim=0)\n",
    "    data = Variable(data, volatile=True)\n",
    "    if args.cuda:\n",
    "        data = data.cuda()\n",
    "    z = model.get_latent_var(data.view(-1, model.nc, model.ndf, model.ngf))\n",
    "    it = iter(z.split(1))\n",
    "    z = zip(it, it)\n",
    "    zs = []\n",
    "    numsample = 11\n",
    "    for i,j in z:\n",
    "        for factor in np.linspace(0,1,numsample):\n",
    "            zs.append(i+(j-i)*factor)\n",
    "    z = torch.cat(zs, 0)\n",
    "    recon = model.decode(z)\n",
    "\n",
    "    it1 = iter(data.split(1))\n",
    "    it2 = [iter(recon.split(1))]*numsample\n",
    "    result = zip(it1, it1, *it2)\n",
    "    result = [im for item in result for im in item]\n",
    "\n",
    "    result = torch.cat(result, 0)\n",
    "    torchvision.utils.save_image(result.data, '../imgs/trans.jpg', nrow=2+numsample, padding=2)\n",
    "\n",
    "\n",
    "def rand_faces(num=5):\n",
    "    load_last_model()\n",
    "    model.eval()\n",
    "    z = torch.randn(num*num, model.latent_variable_size)\n",
    "    z = Variable(z, volatile=True)\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    recon = model.decode(z)\n",
    "    torchvision.utils.save_image(recon.data, '../imgs/rand_faces.jpg', nrow=num, padding=2)\n",
    "\n",
    "# def load_last_model():\n",
    "#     models = glob('../models/*.pth')\n",
    "#     model_ids = [(int(f.split('_')[1]), f) for f in models]\n",
    "#     start_epoch, last_cp = max(model_ids, key=lambda item:item[0])  # max returns the model_id with the largest proxy value (item)\n",
    "#     model.load_state_dict(torch.load(last_cp))\n",
    "#     return start_epoch, last_cp\n",
    "\n",
    "def start_training():\n",
    "    # start_epoch, _ = load_last_model()\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch + 1, start_epoch + args.epochs + 1):\n",
    "        train_loss = train(epoch)\n",
    "        test_loss = test(epoch)\n",
    "        torch.save(model.state_dict(), '../models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))\n",
    "\n",
    "def last_model_to_cpu():\n",
    "    _, last_cp = load_last_model()\n",
    "    model.cpu()\n",
    "    torch.save(model.state_dict(), '../models/cpu_'+last_cp.split('/')[-1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_training()\n",
    "    # last_model_to_cpu()\n",
    "    # load_last_model()\n",
    "    # rand_faces(10)\n",
    "    # da = load_pickle(test_loader[0])\n",
    "    # da = da[:120]\n",
    "    # it = iter(da)\n",
    "    # l = zip(it, it, it)\n",
    "    # # latent_space_transition(l)\n",
    "    # perform_latent_space_arithmatics(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
